{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unable to load image dataset\\.git\\.COMMIT_EDITMSG.swp\n",
      "Error: Unable to load image dataset\\.git\\COMMIT_EDITMSG\n",
      "Error: Unable to load image dataset\\.git\\config\n",
      "Error: Unable to load image dataset\\.git\\description\n",
      "Error: Unable to load image dataset\\.git\\HEAD\n",
      "Error: Unable to load image dataset\\.git\\hooks\n",
      "Error: Unable to load image dataset\\.git\\index\n",
      "Error: Unable to load image dataset\\.git\\info\n",
      "Error: Unable to load image dataset\\.git\\logs\n",
      "Error: Unable to load image dataset\\.git\\objects\n",
      "Error: Unable to load image dataset\\.git\\refs\n",
      "Processed and saved preprocessed_dataset\\Aniket-22010103005\\Aniket-22010103005_0.jpg\n",
      "No face detected in dataset\\Aniket-22010103005\\Aniket-22010103005_1.jpg\n",
      "No face detected in dataset\\Aniket-22010103005\\Aniket-22010103005_2.jpg\n",
      "Processed and saved preprocessed_dataset\\Aryan Mahajan - 22010103011\\Aryan Mahajan - 22010103011_0.jpg\n",
      "No face detected in dataset\\Aryan Mahajan - 22010103011\\Aryan Mahajan - 22010103011_1.jpg\n",
      "No face detected in dataset\\Aryan Mahajan - 22010103011\\Aryan Mahajan - 22010103011_2.jpg\n",
      "Processed and saved preprocessed_dataset\\Harshita Rajput - 22010103020\\Harshita Rajput - 22010103020_0.jpg\n",
      "Processed and saved preprocessed_dataset\\Harshita Rajput - 22010103020\\Harshita Rajput - 22010103020_1.jpg\n",
      "Processed and saved preprocessed_dataset\\Harshita Rajput - 22010103020\\Harshita Rajput - 22010103020_2.jpg\n",
      "Processed and saved preprocessed_dataset\\Kanan Verma - 22010103024\\Kanan Verma - 22010103024_0.jpg\n",
      "Processed and saved preprocessed_dataset\\Kanan Verma - 22010103024\\Kanan Verma - 22010103024_1.jpg\n",
      "Processed and saved preprocessed_dataset\\Kanan Verma - 22010103024\\Kanan Verma - 22010103024_2.jpg\n",
      "Processed and saved preprocessed_dataset\\Karan Sharma - 22010103026\\Karan Sharma - 22010103026_0.jpg\n",
      "Processed and saved preprocessed_dataset\\Karan Sharma - 22010103026\\Karan Sharma - 22010103026_1.jpg\n",
      "Processed and saved preprocessed_dataset\\Karan Sharma - 22010103026\\Karan Sharma - 22010103026_2.jpg\n",
      "Processed and saved preprocessed_dataset\\Nitin Rao - 22010103037\\Nitin Rao - 22010103037_0.jpg\n",
      "Processed and saved preprocessed_dataset\\Nitin Rao - 22010103037\\Nitin Rao - 22010103037_1.jpg\n",
      "Processed and saved preprocessed_dataset\\Nitin Rao - 22010103037\\Nitin Rao - 22010103037_2.jpg\n",
      "Processed and saved preprocessed_dataset\\Preeti Thakur - 22010103038\\Preeti Thakur - 22010103038_0.jpg\n",
      "Processed and saved preprocessed_dataset\\Preeti Thakur - 22010103038\\Preeti Thakur - 22010103038_1.jpg\n",
      "Processed and saved preprocessed_dataset\\Shagun Sharma - 22010103057\\Shagun Sharma - 22010103070_0.jpg\n",
      "Processed and saved preprocessed_dataset\\Shagun Sharma - 22010103057\\Shagun Sharma - 22010103070_1.jpg\n",
      "Processed and saved preprocessed_dataset\\Shagun Sharma - 22010103057\\Shagun Sharma - 22010103070_2.jpg\n",
      "Processed and saved preprocessed_dataset\\Shamak Chouhan Ghantoo - 2201010103059\\Shamak Chouhan Ghantoo - 2201010103059_0.jpg\n",
      "Processed and saved preprocessed_dataset\\Shamak Chouhan Ghantoo - 2201010103059\\Shamak Chouhan Ghantoo - 2201010103059_1.jpg\n",
      "No face detected in dataset\\Shamak Chouhan Ghantoo - 2201010103059\\Shamak Chouhan Ghantoo - 2201010103059_2.jpg\n",
      "Processed and saved preprocessed_dataset\\Shreya Thakur - 22010103061\\Shreya Thakur - 22010103061_0.jpg\n",
      "Processed and saved preprocessed_dataset\\Shreya Thakur - 22010103061\\Shreya Thakur - 22010103061_1.jpg\n",
      "Processed and saved preprocessed_dataset\\Shreya Thakur - 22010103061\\Shreya Thakur - 22010103061_2.jpg\n",
      "Processed and saved preprocessed_dataset\\Suryansh Sharma - 22010103070\\Suryansh Sharma_0.jpg\n",
      "No face detected in dataset\\Suryansh Sharma - 22010103070\\Suryansh Sharma_1.jpg\n",
      "No face detected in dataset\\Suryansh Sharma - 22010103070\\Suryansh Sharma_2.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Load the Haar Cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Function to preprocess an image\n",
    "def preprocess_image(image_path, output_path, target_size=(150, 150)):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Unable to load image {image_path}\")\n",
    "        return\n",
    "\n",
    "    # Convert to grayscale (optional but recommended)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    if len(faces) == 0:\n",
    "        print(f\"No face detected in {image_path}\")\n",
    "        return\n",
    "\n",
    "    # Assume the first face is the target\n",
    "    (x, y, w, h) = faces[0]\n",
    "\n",
    "    # Crop the face\n",
    "    face = gray[y:y+h, x:x+w]\n",
    "\n",
    "    # Resize the face to the target size\n",
    "    resized = cv2.resize(face, target_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Save the preprocessed image\n",
    "    cv2.imwrite(output_path, resized)\n",
    "    print(f\"Processed and saved {output_path}\")\n",
    "\n",
    "# Function to preprocess the entire dataset\n",
    "def preprocess_dataset(input_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for person_name in os.listdir(input_folder):\n",
    "        person_folder = os.path.join(input_folder, person_name)\n",
    "        output_person_folder = os.path.join(output_folder, person_name)\n",
    "        if not os.path.exists(output_person_folder):\n",
    "            os.makedirs(output_person_folder)\n",
    "\n",
    "        for image_name in os.listdir(person_folder):\n",
    "            image_path = os.path.join(person_folder, image_name)\n",
    "            output_path = os.path.join(output_person_folder, image_name)\n",
    "            preprocess_image(image_path, output_path)\n",
    "\n",
    "# Preprocess the dataset\n",
    "input_folder = \"dataset\"  # Folder containing raw images\n",
    "output_folder = \"preprocessed_dataset\"  # Folder to save preprocessed images\n",
    "preprocess_dataset(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "\n",
    "# Initialize face detector and landmark predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")  # Download this file\n",
    "\n",
    "# Function to preprocess an image\n",
    "def preprocess_image(image_path, output_path, target_size=(160, 160)):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Unable to load image {image_path}\")\n",
    "        return\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = detector(gray)\n",
    "    if len(faces) == 0:\n",
    "        print(f\"No face detected in {image_path}\")\n",
    "        return\n",
    "\n",
    "    # Assume the first face is the target\n",
    "    face = faces[0]\n",
    "\n",
    "    # Detect facial landmarks\n",
    "    shape = predictor(gray, face)\n",
    "    shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "    # Extract the eyes and nose for alignment\n",
    "    left_eye = shape[36:42]\n",
    "    right_eye = shape[42:48]\n",
    "    nose = shape[27:31]\n",
    "\n",
    "    # Calculate the center of the eyes\n",
    "    left_eye_center = left_eye.mean(axis=0).astype(int)\n",
    "    right_eye_center = right_eye.mean(axis=0).astype(int)\n",
    "\n",
    "    # Calculate the angle between the eyes\n",
    "    dY = right_eye_center[1] - left_eye_center[1]\n",
    "    dX = right_eye_center[0] - left_eye_center[0]\n",
    "    angle = np.degrees(np.arctan2(dY, dX))\n",
    "\n",
    "    # Calculate the center of the face\n",
    "    face_center = (face.left() + face.right()) // 2, (face.top() + face.bottom()) // 2\n",
    "\n",
    "    # Rotate the image to align the eyes\n",
    "    M = cv2.getRotationMatrix2D(face_center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]), flags=cv2.INTER_CUBIC)\n",
    "\n",
    "    # Crop the face\n",
    "    (x, y, w, h) = cv2.boundingRect(np.array([left_eye_center, right_eye_center, nose.mean(axis=0)]))\n",
    "    cropped = rotated[y:y+h, x:x+w]\n",
    "\n",
    "    # Resize the face to the target size\n",
    "    resized = cv2.resize(cropped, target_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Normalize lighting\n",
    "    resized = cv2.equalizeHist(cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "    # Save the preprocessed image\n",
    "    cv2.imwrite(output_path, resized)\n",
    "    print(f\"Processed and saved {output_path}\")\n",
    "\n",
    "# Function to preprocess the entire dataset\n",
    "def preprocess_dataset(input_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for person_name in os.listdir(input_folder):\n",
    "        person_folder = os.path.join(input_folder, person_name)\n",
    "        output_person_folder = os.path.join(output_folder, person_name)\n",
    "        if not os.path.exists(output_person_folder):\n",
    "            os.makedirs(output_person_folder)\n",
    "\n",
    "        for image_name in os.listdir(person_folder):\n",
    "            image_path = os.path.join(person_folder, image_name)\n",
    "            output_path = os.path.join(output_person_folder, image_name)\n",
    "            preprocess_image(image_path, output_path)\n",
    "\n",
    "# Preprocess the dataset\n",
    "input_folder = \"dataset\"  # Folder containing raw images\n",
    "output_folder = \"preprocessed_dataset\"  # Folder to save preprocessed images\n",
    "preprocess_dataset(input_folder, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_recognition_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
